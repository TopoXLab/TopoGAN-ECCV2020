{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Include.ipynb\n",
    "%run Net.ipynb\n",
    "%run Data.ipynb\n",
    "%run Topo_treatment.ipynb\n",
    "%run Viewer.ipynb\n",
    "        \n",
    "class GAN(object):\n",
    "    \n",
    "    def __init__(self, general, adv_params, G_arch, D_arch):\n",
    "        \n",
    "        lr        = general[\"learning_rate\"]\n",
    "        beta1     = general[\"beta1\"]\n",
    "        beta2     = general[\"beta2\"]\n",
    "        loss_mode = general[\"loss\"]\n",
    "        reduction = general[\"reduction\"]\n",
    "        \n",
    "        self.N_critic = adv_params[\"wgangp\"][\"N_CRITIC\"]\n",
    "        \n",
    "        cudnn.benchmark = FLAGS.cudnn_benchmark\n",
    "        gpu_num     = FLAGS.gpu_num\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                      and FLAGS.gpu_enable else \"cpu\")\n",
    "        torch.manual_seed(random.randint(1, 10000))\n",
    "        \n",
    "        self.inputG_dims, G_layers = Net.parse_layers(G_arch)\n",
    "        self.inputD_dims, D_layers = Net.parse_layers(D_arch)\n",
    "        self.netG = Network_template(gpu_num, G_layers).to(self.device)\n",
    "        Net.init_weights(self.netG, \"normal\")\n",
    "        self.netD = Network_template(gpu_num, D_layers).to(self.device)\n",
    "        Net.init_weights(self.netD, \"normal\")\n",
    "        \n",
    "        self.et         = Edges_(adv_params, debug=False)\n",
    "        self.criterion  = GANLoss(loss_mode, reduction).to(self.device)\n",
    "        self.criterionT = GANLoss(\"vanilla_topo\", \"sum\").to(self.device)\n",
    "        self.optimizerD = optim.Adam(self.netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        #self.optimizerD = optim.Adam(filter(lambda p: p.requires_grad, self.netD.parameters()), lr=lr, betas=(beta1,beta2))\n",
    "        self.optimizerG = optim.Adam(self.netG.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        \n",
    "    def save_noise_(self, shape, name):\n",
    "        '''\n",
    "        shape: shape of the noise, usually it is [batch_size, 128, 1, 1]\n",
    "        name: should be like 128_128_1_1_0.dat\n",
    "        all noise are saved under D:/Data/fixed_z/\n",
    "        '''\n",
    "        z_ = torch.randn(shape, device=self.device)\n",
    "        FileIO.write_binary('D:/Data/fixed_z/'+name, z_.cpu().numpy().flatten(), list(z_.shape), 'f')\n",
    "        \n",
    "    def sample_(self, shape):\n",
    "        z_ = torch.randn(shape, device=self.device)\n",
    "        return self.netG(z_)\n",
    "    \n",
    "    def sample_save_(self, name, shape, direc, scalor, offset):\n",
    "        '''\n",
    "        shape: shape of the noise, usually it is [batch_size, 128, 1, 1]\n",
    "        name: should be like 128_128_1_1_0.dat\n",
    "        all noise are saved under D:/Data/fixed_z/\n",
    "        '''\n",
    "        Path(direc).mkdir(parents=True, exist_ok=True)\n",
    "        if FLAGS.continue_model:\n",
    "            self.netG.load_state_dict(torch.load('%s/netG_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.netD.load_state_dict(torch.load('%s/netD_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            print(\"Models loaded at step %d\" % FLAGS.model_step)\n",
    "        \n",
    "        i = 0\n",
    "        interval = 1000\n",
    "        z_ = FileIO.read_binary('D:/Data/fixed_z/'+name, shape, 'f')\n",
    "        while True:\n",
    "            si = i\n",
    "            se = np.min((si + interval, z_.shape[0]))\n",
    "            z_sub_ = z_[si:se,:]\n",
    "            z_sub_ = torch.from_numpy(z_sub_).to(self.device)\n",
    "            samples = self.netG(z_sub_)\n",
    "            FileIO.save_image_batch(samples.detach().cpu().numpy(), direc, 'gen', scalor, si)\n",
    "            i = se\n",
    "            if i >= z_.shape[0]:\n",
    "                break\n",
    "     \n",
    "    def D_iteration(self, Dreal_device, Dfake_device):\n",
    "        self.netD.zero_grad()      \n",
    "        errD = self.criterion([\"D\", self.netD, self.device, Dreal_device, Dfake_device])\n",
    "        errD.backward()\n",
    "        self.optimizerD.step()\n",
    "        return errD.item()\n",
    "    \n",
    "    def G_iteration(self, Dfake_device, withTopo):\n",
    "        self.netG.zero_grad()\n",
    "        errG = self.criterion([\"G\", self.netD, Dfake_device])\n",
    "        errG.backward(retain_graph=withTopo)\n",
    "   \n",
    "        if withTopo:\n",
    "            tp_wgt   = self.et.return_tp_weight()\n",
    "            fake_fix, mean_wasdis = self.et.fix_with_topo(Dfake_device.detach().cpu().numpy(),\n",
    "                                    self.et.return_target_dim(), -1.0, 1.0, blind=self.et.blind())\n",
    "            fake_fix = torch.from_numpy(fake_fix).to(self.device)\n",
    "            errT     = self.criterionT([Dfake_device, fake_fix]) * tp_wgt\n",
    "            errT.backward()\n",
    "            self.optimizerG.step()\n",
    "            return [errG.item(), errT.item(), mean_wasdis]\n",
    "        self.optimizerG.step()\n",
    "        return errG.item()\n",
    "\n",
    "    def train(self, data_params, withTopo):       \n",
    "        epochs        = data_params[\"epochs\"]\n",
    "        batch_size    = data_params[\"batch_size\"]\n",
    "        batch_workers = data_params[\"batch_workers\"]\n",
    "        shuffle       = data_params[\"shuffle\"]\n",
    "        drop_last     = data_params[\"drop_last\"]\n",
    "        dataloader    = Data_fetcher.fetch_dataset(FLAGS.dataset, batch_size, batch_workers, shuffle, drop_last, 0.5)\n",
    "        log           = open(FLAGS.log_path, \"a\")\n",
    "        \n",
    "        step = 0\n",
    "        if withTopo:\n",
    "            self.et.load_pd_pool(FLAGS.pds_path, \"dat\", 1.0, batch_size)\n",
    "        if FLAGS.continue_model:\n",
    "            self.netG.load_state_dict(torch.load('%s/netG_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            self.netD.load_state_dict(torch.load('%s/netD_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "        \n",
    "        g_lrec = []\n",
    "        d_lrec = []\n",
    "        #fixed_z_ = FileIO.read_binary('D:/Data/fixed_z/128_128_1_1_0.dat', [batch_size]+self.inputG_dims, 'f')\n",
    "        #fixed_z_ = torch.from_numpy(fixed_z_).to(self.device)\n",
    "        fixed_z_ = torch.randn([128,128,1,1], device=self.device)\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(dataloader, 0):               \n",
    "                Dreal_device = data['image'].to(self.device)\n",
    "                Dfake_device = self.sample_([data['image'].shape[0]]+self.inputG_dims)\n",
    "                d_lrec.append(self.D_iteration(Dreal_device, Dfake_device))\n",
    "                \n",
    "                if step % self.N_critic == 0:\n",
    "                    Dfake_device = self.sample_([data['image'].shape[0]]+self.inputG_dims)\n",
    "                    g_lrec.append(self.G_iteration(Dfake_device, withTopo))\n",
    "                step = step + 1\n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    if withTopo:\n",
    "                        msg = ('[%d/%d][%d/%d] D_loss: %.4f G_loss: %.4f T_loss: %.4f Wasserstein_dist: %.4f Step: %d'\n",
    "                          %(epoch, epochs, i, len(dataloader), np.mean(np.asarray(d_lrec)), np.mean(np.asarray(g_lrec)[:,0]),\n",
    "                            np.mean(np.asarray(g_lrec)[:,1]), np.mean(np.asarray(g_lrec)[:,2]), step))\n",
    "                    else:        \n",
    "                        msg = ('[%d/%d][%d/%d] D_loss: %.4f G_loss: %.4f Step: %d'\n",
    "                          %(epoch, epochs, i, len(dataloader), np.mean(np.asarray(d_lrec)), np.mean(np.asarray(g_lrec)), step))\n",
    "                    g_lrec[:] = []\n",
    "                    d_lrec[:] = []\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                if step % FLAGS.save_step == 0:\n",
    "                    # ===== Save images ====\n",
    "                    Dfake_device_ = self.netG(fixed_z_)\n",
    "                    vutils.save_image(Dfake_device_.detach().cpu(),\n",
    "                    '%s/generated_step_%d.png' % (FLAGS.image_save, step), normalize=True)\n",
    "                    if withTopo:\n",
    "                        fix_, _ = self.et.fix_with_topo(Dfake_device_.detach().cpu().numpy(),\n",
    "                                self.et.return_target_dim(), -1.0, 1.0, blind=self.et.blind())\n",
    "                        fix_    = torch.from_numpy(np.expand_dims(fix_, axis=1))\n",
    "                        vutils.save_image(fix_,\n",
    "                        '%s/topo_step_%d.png' % (FLAGS.image_save, step), normalize=True)\n",
    "                    # ===== Save models ====\n",
    "                    torch.save(self.netG.state_dict(), '%s/netG_step_%d.pth' % (FLAGS.model_save, step))\n",
    "                    torch.save(self.netD.state_dict(), '%s/netD_step_%d.pth' % (FLAGS.model_save, step))\n",
    "\n",
    "        log.close()\n",
    "        print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
