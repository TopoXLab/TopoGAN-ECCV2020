{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Topo_treatment.ipynb\n",
    "%run Utility_general.ipynb\n",
    "import glob\n",
    "import struct\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image as PImg\n",
    "\n",
    "dlength_dict = {'f': 4, 'd': 8}\n",
    "\n",
    "class FileIO(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_binary(path, shape, dtype='d'):\n",
    "        file_in  = open(path, \"rb\")\n",
    "        data_arr = struct.unpack(str(np.prod(shape))+dtype, file_in.read(dlength_dict[dtype]*np.prod(shape)))\n",
    "        data_arr = np.reshape(data_arr, shape)\n",
    "        file_in.close()\n",
    "        if dtype=='f':\n",
    "            data_arr = np.float32(data_arr)\n",
    "        return data_arr\n",
    "    \n",
    "    @staticmethod\n",
    "    def write_binary(path, data, shape, dtype='d'):\n",
    "        '''\n",
    "        data has to be flattened.\n",
    "        '''\n",
    "        file_out = open(path, \"wb\")\n",
    "        file_out.write(struct.pack(str(np.prod(shape))+dtype, *(data)))\n",
    "        file_out.close()\n",
    "        \n",
    "    @staticmethod\n",
    "    def read_matrix_binary(path, dtype='d'):\n",
    "        file_in = open(path, \"rb\")\n",
    "        dims    = struct.unpack('I', file_in.read(4))[0]\n",
    "        if dims == 0:\n",
    "            return None\n",
    "        shape   = struct.unpack(str(dims)+'I', file_in.read(4 * dims))\n",
    "        mat     = struct.unpack(str(np.prod(shape))+dtype, file_in.read(dlength_dict[dtype]*np.prod(shape)))\n",
    "        mat     = np.reshape(mat, shape)\n",
    "        return mat\n",
    "        \n",
    "    @staticmethod\n",
    "    def write_matrix_binary(path, mat, dtype='d'):\n",
    "        dims  = len(mat.shape)\n",
    "        shape = mat.shape\n",
    "        file_out = open(path, \"wb\")\n",
    "        file_out.write(struct.pack('I', dims))\n",
    "        file_out.write(struct.pack(str(dims)+'I', *(shape)))\n",
    "        file_out.write(struct.pack(str(np.prod(shape))+dtype, *(mat.flatten())))\n",
    "        file_out.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_pim_save(dir_in, dir_out, ext_in, params, reg=0, writeout=True, give_status=False):\n",
    "        address_book_in  = []\n",
    "        address_book_out = []\n",
    "        os.chdir(dir_in)\n",
    "        for file in glob.glob(\"*.\"+ext_in):\n",
    "            address_book_in.append(os.path.join(dir_in, file))\n",
    "            address_book_out.append(os.path.join(dir_out, file+\".dat\"))\n",
    "        if writeout:\n",
    "            Path(dir_out).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        max_rec = []\n",
    "        min_rec = []\n",
    "        et      = Edges_(params, False)\n",
    "        num_    = len(address_book_in)\n",
    "        for i in range(num_):\n",
    "            img = np.expand_dims(skio.imread(address_book_in[i]), 0)\n",
    "            pim = np.squeeze(et.persimg_batch(img, binarize=True))\n",
    "            pim = (pim - reg) / reg\n",
    "            if writeout:\n",
    "                FileIO.write_binary(address_book_out[i], pim.flatten(), pim.shape)\n",
    "            if i % 49 == 0:\n",
    "                print(\"%d/%d\" %(i+1, num_))\n",
    "            if give_status:\n",
    "                max_rec.append(np.amax(pim))\n",
    "                min_rec.append(np.amin(pim))\n",
    "        \n",
    "        if give_status:\n",
    "            print(np.amax(max_rec), np.amin(min_rec))\n",
    "            \n",
    "    @staticmethod\n",
    "    def compute_pd_save(dir_in, dir_out, ext_in, params, dim, reg):\n",
    "        '''\n",
    "        reg: if True, images will be regularized\n",
    "        '''\n",
    "        address_book_in  = []\n",
    "        address_book_out = []\n",
    "        os.chdir(dir_in)\n",
    "        for file in glob.glob(\"*.\"+ext_in):\n",
    "            address_book_in.append(os.path.join(dir_in, file))\n",
    "            address_book_out.append(os.path.join(dir_out, file+\".dat\"))\n",
    "        Path(dir_out).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        et   = Edges_(params, False)\n",
    "        num_ = len(address_book_in)\n",
    "        for i in range(num_):\n",
    "            img = skio.imread(address_book_in[i])\n",
    "            if reg:\n",
    "                img = Utility_general.normalize_data_([img], 127.5)[0]\n",
    "            img = np.expand_dims(img, 0)\n",
    "            _, _, _, _, pd = et.pd_batch(img, dim, debug=False, old_form=True, binarize=True, disttrfm=True)\n",
    "            pd = np.squeeze(np.asarray(pd))\n",
    "            FileIO.write_matrix_binary(address_book_out[i], pd)\n",
    "            if i % 49 == 0:\n",
    "                print(\"%d/%d\" %(i+1, num_))\n",
    "                \n",
    "    @staticmethod\n",
    "    def read_pd_subset(dir_in, ext_in, percentage, shuffle=True, dummyifempty=False):\n",
    "        '''\n",
    "        Note, there are pds with one point or zero point from time to time.\n",
    "        if dummyifempty is True, EMPTY PDs will be inserted [0., .5].\n",
    "        '''\n",
    "        address_book_in = []\n",
    "        filename_book   = []\n",
    "        os.chdir(dir_in)\n",
    "        for file in glob.glob(\"*.\"+ext_in):\n",
    "            address_book_in.append(os.path.join(dir_in, file))\n",
    "            filename_book.append(file[:-(len(ext_in)+1)])\n",
    "        file_num = len(address_book_in)\n",
    "        read_num = int(np.floor(file_num * percentage))\n",
    "        if shuffle:\n",
    "            ind_list = random.sample(range(file_num), read_num)\n",
    "        else:\n",
    "            ind_list = np.arange(read_num)\n",
    "        \n",
    "        pd_set = []\n",
    "        f_set  = []\n",
    "        for i in range(read_num):\n",
    "            pd_ = FileIO.read_matrix_binary(address_book_in[ind_list[i]])\n",
    "            if pd_.any() != None:\n",
    "                if len(pd_.shape) == 1:\n",
    "                    pd_ = np.expand_dims(pd_, axis=0)\n",
    "                if pd_.shape[1] == 0 and dummyifempty:\n",
    "                    pd_ = np.expand_dims(np.array([0., .5]), axis=0)\n",
    "                pd_set.append(pd_)\n",
    "                f_set.append(filename_book[ind_list[i]])\n",
    "        return pd_set, f_set\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_pd_pathlist(pd_pathlist):\n",
    "        '''\n",
    "        Read persistence diagrams from the given path list.\n",
    "        Each path should be a full path.\n",
    "        '''\n",
    "        file_num = len(pd_pathlist)\n",
    "        pd_set   = [None] * file_num\n",
    "        for i in range(file_num):\n",
    "            pd_set[i] = FileIO.read_matrix_binary(pd_pathlist[i])\n",
    "        return pd_set\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_image_batch(data, folder, prefix, scalor, number_offset, num=-1):\n",
    "        '''\n",
    "        data: the image data to be saved\n",
    "        folder: the path to the folder where the images are saved\n",
    "        prefix: prefix_00000.png\n",
    "        scalor: data * scalor + scalor\n",
    "        number_offset: the index of the image to start saving from (included)\n",
    "        num: number of images to save out, -1 means all\n",
    "        '''\n",
    "        data = np.squeeze(data)\n",
    "        assert(len(data.shape) == 3 or len(data.shape) == 4)\n",
    "        batch_size  = data.shape[0]\n",
    "        image_shape = data.shape[-2:]\n",
    "        \n",
    "        if num == -1 or num >= batch_size:\n",
    "            out_num = batch_size\n",
    "        else:\n",
    "            out_num = num\n",
    "            \n",
    "        for idx in range(out_num):\n",
    "            out_name = ''\n",
    "            for _ in range(5 - len(str(idx + number_offset))):\n",
    "                out_name += '0'\n",
    "            out_name = folder + \"/\" + prefix + \"_\" + out_name + str(idx + number_offset) + \".png\"           \n",
    "            dat_ = np.reshape(data[idx], image_shape)\n",
    "            dat_ = dat_ * scalor + scalor\n",
    "            dat_ = dat_.astype(np.uint8)\n",
    "            cv2.imwrite(out_name, dat_)\n",
    "        print(\"Data write out complete.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_mask_unet(source_folder, target_folder, source_ext, target_ext):\n",
    "        '''\n",
    "        The mask required by unet is 0 or 1, convert 0 - 255 mask to 0 or 1.\n",
    "        '''\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "        os.chdir(source_folder)\n",
    "        for file in glob.glob(\"*.\" + source_ext):\n",
    "            name = os.path.join(source_folder, file)\n",
    "            img  = PImg.open(name)\n",
    "            img  = np.array(img)\n",
    "            img[img <= 127.5] = 0\n",
    "            img[img  > 127.5] = 1\n",
    "            \n",
    "            out_name = file[:-len(source_ext)-1] + \"_mask.\" + target_ext\n",
    "            out_name = os.path.join(target_folder, out_name)\n",
    "            res = PImg.fromarray(img.astype(np.uint8))\n",
    "            res.save(out_name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_google_maps_2_binary(source_folder, source_ext, target_folder, target_ext, threshold, radius, iter_num):\n",
    "        '''\n",
    "        This function converts RGB google maps to grayscale maps.\n",
    "        threshold, integer, blow which pixels considered background (252 usually).\n",
    "        radius, integer, kernel radius (2 usually).\n",
    "        iter_num, number of iterations for the dilate and erode (5 usually).\n",
    "        '''\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "        os.chdir(source_folder)\n",
    "        kernel = np.ones((radius, radius), np.uint8)\n",
    "        for file in glob.glob(\"*.\" + source_ext):\n",
    "            name = os.path.join(source_folder, file)\n",
    "            img  = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
    "            img[img < threshold] = 0\n",
    "            img = cv2.dilate(img, kernel, iterations=iter_num)\n",
    "            img = cv2.erode(img, kernel, iterations=iter_num)\n",
    "            img = 255 - img\n",
    "\n",
    "            out_name = file[:-len(source_ext)-1] + \".\" + target_ext\n",
    "            out_name = os.path.join(target_folder, out_name)\n",
    "            cv2.imwrite(out_name, img)\n",
    "            \n",
    "    @staticmethod\n",
    "    def convert_facades_2_binary(source_folder, source_ext, target_folder, target_ext,\n",
    "        red_thresh, gray_thresh, radius, iter_num, resize_height, resize_width, border_thickness=0):\n",
    "        '''\n",
    "        This function converts facades to grayscale maps.\n",
    "        red_thresh, integer, controls red channel below which set to 0 (150)\n",
    "        gray_thresh, integer, watershed for 0 or 255 (80)\n",
    "        radius, integer, kernel radius (2 usually).\n",
    "        iter_num, number of iterations for the dilate and erode (5 usually).\n",
    "        '''\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "        os.chdir(source_folder)\n",
    "        kernel = np.ones((radius, radius), np.uint8)\n",
    "        for file in glob.glob(\"*.\" + source_ext):\n",
    "            name = os.path.join(source_folder, file)\n",
    "            img  = cv2.imread(name, cv2.IMREAD_GRAYSCALE)\n",
    "            imc  = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            c_r  = imc[:,:,2]\n",
    "            c_r[c_r < red_thresh] = 0\n",
    "            img  = img + c_r\n",
    "            img[img < gray_thresh] = 0\n",
    "            img[img >= gray_thresh] = 255\n",
    "            bnd, hcy, red = Utility_topo.compute_bnd_red_cv(img, 0, 255, 8)\n",
    "            \n",
    "            h = img.shape[0]\n",
    "            w = img.shape[1]\n",
    "            cur = np.ones((h, w)) * 255\n",
    "            for i in range(len(bnd)):\n",
    "                for j in range(len(bnd[i])):\n",
    "                    cur[bnd[i][j][0][1], bnd[i][j][0][0]] = 0\n",
    "            \n",
    "            cur = cv2.erode(cur, kernel, iterations=iter_num)\n",
    "            cur = cv2.resize(cur,(resize_height,resize_width))\n",
    "            cur[cur < 255] = 0\n",
    "            if border_thickness > 0:\n",
    "                cv2.rectangle(cur, (0, 0), (cur.shape[0]-1, cur.shape[1]-1), (0), border_thickness)\n",
    "\n",
    "            out_name = file[:-len(source_ext)-1] + \".\" + target_ext\n",
    "            out_name = os.path.join(target_folder, out_name)\n",
    "            cv2.imwrite(out_name, cur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
