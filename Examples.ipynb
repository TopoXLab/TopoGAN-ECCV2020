{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "===== Descriptions\n",
    "Read in images, do the thinning on the images, extract 0-dim topological\n",
    "features from the results.\n",
    "'''\n",
    "from skimage.morphology import skeletonize, thin\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import invert\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "%run Viewer.ipynb\n",
    "%run Topo_treatment.ipynb\n",
    "%run Archpool.ipynb\n",
    "\n",
    "img = [None] * 3\n",
    "img[0] = cv2.imread(\"D:/Data/cremi_exp/cremi_gen/gen_00098.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img[1] = cv2.imread(\"D:/Data/cremi_exp/cremi_gen/gen_00099.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_ = copy.copy(img[1])\n",
    "img_[img_ < 127.5] = 0\n",
    "img_[img_ >= 127.5] = 1\n",
    "skeleton = thin(1 - img_)\n",
    "img_ = 1 - skeleton\n",
    "img_[img_ == 1] = 255\n",
    "img_[img_ == 0] = 0\n",
    "img[2] = img_\n",
    "\n",
    "img = Utility_general.normalize_data_(img, 127.5)\n",
    "img = np.asarray(img)\n",
    "img_bin = Utility_topo.binarize_data(img, 0.0)\n",
    "\n",
    "adv_params = return_advanced_params()\n",
    "et = Edges_(adv_params, False)\n",
    "B_, D_, PD_, tsfm_list, bnd_ph, red_ph = et.pd_batch(img_bin, 0, debug=True)\n",
    "\n",
    "Viewer.imshow_(img_bin[2])\n",
    "x_, y_ = Viewer.draw_bnd_or_red_on_single_dim(img_bin[2], red_ph[2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Select two end points on a 64 x 64 images and find the line segment between\n",
    "them. The thickness can be adjusted.\n",
    "'''\n",
    "%run Viewer.ipynb\n",
    "%run Utility_general.ipynb\n",
    "import time\n",
    "\n",
    "aa = np.array([[16, 55], [17, 56]])\n",
    "bb = Utility_general.connect_2pts(aa, (64, 64), 1)\n",
    "x_, y_ = Utility_general.connect_2pts(aa, (64, 64), 3, split_form=True)\n",
    "img = np.ones((64, 64)) * 255\n",
    "print(bb)\n",
    "\n",
    "for i in range(bb.shape[0]):\n",
    "    img[bb[i,1], bb[i,0]] = 0\n",
    "Viewer.imshow_(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate a random distance matrix, solve the linear programming problem\n",
    "and return the match (mapping)\n",
    "'''\n",
    "%run Topo_treatment.ipynb\n",
    "import numpy as np\n",
    "\n",
    "dist = np.random.random_sample((3, 3))\n",
    "lpsolver = LPSolver_(3, 3, False)\n",
    "sol = lpsolver.Wasserstein_LP(dist)\n",
    "mapping = lpsolver.approx_OT(sol)\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read batch from generated images and a subset of the computed persistence\n",
    "diagrams. Compute persistence diagrams on the images, filter the pds, and\n",
    "extract only birth time. Computer 1-wasserstein distance and retrieve the\n",
    "mappings via linear programming. Find the dot-to-dot mappings and compute\n",
    "topo force. Compute boundaries and reductions using opencv and finally f-\n",
    "ind the points to be fixed and plot these points on the original images.\n",
    "This example is an exact copy of the core topology component in the GAN.\n",
    "'''\n",
    "\n",
    "%run Archpool.ipynb\n",
    "%run Data.ipynb\n",
    "%run Viewer.ipynb\n",
    "%run Topo_treatment.ipynb\n",
    "%run FileIO.ipynb\n",
    "\n",
    "adv_params = return_advanced_params()\n",
    "et = Edges_(adv_params, False)\n",
    "\n",
    "img_bat = Utility_general.read_image_subset(\"D:/Data/cremi_exp/cremi_gen\", \"png\", 1.0, shuffle=False)\n",
    "img_bat = Utility_general.normalize_data_(img_bat, 127.5)\n",
    "img_bat = np.asarray(img_bat)\n",
    "img_bin = Utility_topo.binarize_data(img_bat, 0.0)\n",
    "\n",
    "B_, D_, set1, _, bnd_ph, red_ph = et.pd_batch(img_bin, 1, debug=True, old_form=False, binarize=False)\n",
    "set2, f2        = FileIO.read_pd_subset(\"D:/Data/cremi_patch64/pds\", \"dat\", 0.005, shuffle=False)\n",
    "B_, D_, set1    = Utility_topo.topo_filter_retmat_mul(B_, D_, set1, 1.0)\n",
    "set2            = Utility_topo.topo_filter_retmat(set2, 1.0)\n",
    "\n",
    "b1 = Utility_topo.extract_dim_from_list(set1, 0)\n",
    "b2 = Utility_topo.extract_dim_from_list(set2, 0)\n",
    "lp_ = LPSolver_(len(b1), len(b2), False)\n",
    "dist, G = Utility_general.wasserstein_set_distance(b1, b2, 1.0)\n",
    "mapping, dist, G = lp_.linear_program_(dist, G)\n",
    "force = Utility_topo.topo_force_(b1, b2, G, mapping)\n",
    "\n",
    "bnd_cv, hcy_cv, red_cv = Utility_topo.compute_bnd_red_cv_batch(img_bin)\n",
    "flt_list, frc_x_, frc_y_ = Utility_topo.apply_force_(b1, force, B_,\n",
    "                           bnd_cv, hcy_cv, 2, True, True, True, (64, 64), 3)\n",
    "#img_frc = et.plot_on_images(img_bat, frc_x_, frc_y_, -1.0)\n",
    "\n",
    "idx = 20\n",
    "idxx = 0\n",
    "\n",
    "print(\"%d structures in image %d\" %(len(frc_x_[idx]), idx))\n",
    "print('%d points in strcture %d' %(len(frc_x_[idx][idxx]), idxx))\n",
    "\n",
    "print(frc_x_[idx][idxx])\n",
    "print(frc_y_[idx][idxx])\n",
    "print(B_[idx][flt_list[idx][idxx],:])\n",
    "\n",
    "Viewer.draw_coord_on_image([B_[idx][flt_list[idx][idxx],0]], [B_[idx][flt_list[idx][idxx],1]],\n",
    "                           img_bin[idx], (255, 0, 0), color=True)\n",
    "Viewer.draw_coord_on_image(frc_x_[idx][idxx], frc_y_[idx][idxx],\n",
    "                           img_bin[idx], (0, 0, 0), color=True)\n",
    "Viewer.draw_bnd_on_single_dim_cv(img_bin[idx], bnd_cv[idx], (255, 0, 0), -1)\n",
    "\n",
    "'''\n",
    "sub-example: find line segment between two points and plot\n",
    "'''\n",
    "# ends = np.array([B_[idx][flt_list[idx][idxx],:], [frc_x_[idx][idxx][1], frc_y_[idx][idxx][1]]])\n",
    "# x_, y_ = Utility_general.connect_2pts(ends, (64, 64), 5, split_form=True)\n",
    "# Viewer.draw_coord_on_image(x_, y_, img_bin[idx], (255, 0, 0), color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Similiar to example above, except that it calls fix_with_topo routine.\n",
    "'''\n",
    "\n",
    "%run Archpool.ipynb\n",
    "%run Data.ipynb\n",
    "%run Viewer.ipynb\n",
    "%run Topo_treatment.ipynb\n",
    "%run FileIO.ipynb\n",
    "\n",
    "adv_params = return_advanced_params()\n",
    "et = Edges_(adv_params, False)\n",
    "\n",
    "# =========== Targeted topo structure is Dim 1\n",
    "img_bat = Utility_general.read_image_subset(\"D:/Data/facades/test\", \"png\", 1.0, shuffle=False)\n",
    "img_bat = Utility_general.normalize_data_(img_bat, 127.5)\n",
    "img_bat = np.asarray(img_bat)\n",
    "et.load_pd_pool(\"D:/Data/facades/facade128/pds\", \"dat\", 1.0, 32)\n",
    "gen_res, mean_wasdis = et.fix_with_topo(img_bat, 1, -1.0, 1.0, blind=True)\n",
    "\n",
    "# =========== Targeted topo structure is Dim 0\n",
    "# img_bat = Utility_general.read_image_subset(\"D:/Data/Retina/t\", \"png\", 1.0, shuffle=False)\n",
    "# img_bat = Utility_general.normalize_data_(img_bat, 127.5)\n",
    "# img_bat = np.asarray(img_bat)\n",
    "# et.load_pd_pool(\"D:/Data/Retina/retina128/pds\", \"dat\", 1.0, 4)\n",
    "# gen_res, mean_wasdis = et.fix_with_topo_test(img_bat, 0, -1.0, 1.0, blind=True)\n",
    "\n",
    "# idx = 0\n",
    "# Viewer.imshow_(img_bat[idx])\n",
    "# Viewer.imshow_(gen_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "Viewer.imshow_(img_bat[idx])\n",
    "Viewer.imshow_(gen_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example calls of some functions.\n",
    "'''\n",
    "# noise generation and write out\n",
    "fixed_z_ = torch.randn([batch_size]+self.inputG_dims, device=self.device)\n",
    "FileIO.write_binary('D:/Data/fixed_z/128_128_1_1_0.dat', fixed_z_.cpu().numpy().flatten(), list(fixed_z_.shape), 'f')\n",
    "\n",
    "# write out images\n",
    "Dfake_device_ = self.netG(fixed_z_)\n",
    "FileIO.save_image_batch(Dfake_device_.detach().cpu().numpy(), 'D:/tmp', 'gen', 127.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This block converts the mask ranging from 0 to 255 to binary mask with 0 or 1\n",
    "for Unet segmentation purpose.\n",
    "'''\n",
    "%run FileIO.ipynb\n",
    "\n",
    "'''\n",
    "Note Unet requires training images named as cremi_0001.jpg and mask named as cremi_0001_mask.gif\n",
    "while pix2pix requires same names in two folders. Unet needs to convert masks, pix2pix doesn't.\n",
    "'''\n",
    "\n",
    "FileIO.make_mask_unet(\"D:/Data/Retina/compare0.00025\", \"D:/Data/Retina/compare0.00025_maskunet\", 'png', 'gif')\n",
    "#FileIO.convert_google_maps_2_binary(\"D:/Data/maps/map_original_seg\", \"jpg\", \"D:/Data/maps/map_seg\", \"png\", 252, 2, 5)\n",
    "#FileIO.convert_facades_2_binary(\"D:/Data/facades/facade_original_seg\", \"jpg\", \"D:/Data/facades/facade128_maskp2p\", \"jpg\", 150, 80, 2, 2, 128, 128, 1)\n",
    "\n",
    "'''\n",
    "===== Launch docker container:\n",
    "nvidia-docker run -it --name pix2pix -p 8097:8097 -v ~/ptd-shared:/root/shared taesungp/pytorch-cyclegan-and-pix2pix bash\n",
    "===== Generate training images using files in !shared folder!:\n",
    "python datasets/combine_A_and_B.py --fold_A ~/shared/dataset/cremi/cremi64_tx --fold_B ~/shared/dataset/cremi/cremi64_maskp2p --fold_AB ~/shared/dataset/cremi/cremi64_combined\n",
    "python datasets/combine_blank_and_B.py --fold_B ~/shared/dataset/cremi/match0.0005 --fold_AB ~/shared/dataset/cremi/match0.0005_combined\n",
    "===== Train using files from !workplace!:\n",
    "python -m visdom.server &\n",
    "python train.py --dataroot ~/shared/dataset/cremi/cremi64_combined --name cremi64_pix2pix --model pix2pix --netG resnet_9blocks --direction BtoA --resize_or_crop none --gpu_ids '4,5,6,7' --batch_size 8 --input_nc 1 --output_nc 1\n",
    "===== Test using files from !workplace!:\n",
    "python test.py --dataroot ~/shared/dataset/cremi/compare0.0005_combined/ --name cremi64_pix2pix --model pix2pix --direction BtoA --netG resnet_9blocks --gpu_ids '4,5' --num_test 6000 --display_winsize 64 --out_channels 1\n",
    "cp -r results/cremi64_pix2pix/test_latest/images ~/shared/dataset/cremi/compare0.0005_tx\n",
    "rm -r ./results/cremi64_pix2pix/test_latest/images\n",
    "\n",
    "===== Segmentation training:\n",
    "python3 train.py --images /root/shared/dataset/cremi/match0.0005_tx/ --masks /root/shared/dataset/cremi/match0.0005_maskunet/ -e 20 -b 32 -l 0.005 -s 1.0 -c 1 -n match0.0005 --gpu_ids '0'\n",
    "python3 predict.py --infolder ~/shared/a --outfolder ~/shared/b -m checkpoints/match0.0005/CP_epoch19.pth -c 1 -s 1.0 --gpu_ids '2'\n",
    "python3 pix_accuracy.py --resfolder ../b --gthfolder ../c\n",
    "python3 dice_score.py --resfolder ../b --gthfolder ../c\n",
    "'''\n",
    "\n",
    "'''\n",
    "nvidia-docker run -it --name ptgpu01 -p 8888:8888 -p 6006:6006 -v ~/ptd-shared:/root/shared seravee08/lab:10.0-cudnn7-pt1.4.0-notebook-ubuntu18.04-v1.1 bash\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute and save persistence diagrams for training images\n",
    "'''\n",
    "%run FileIO.ipynb\n",
    "%run Archpool.ipynb\n",
    "\n",
    "root = 'D:/Data/facades/facade128'\n",
    "adv_params = return_advanced_params()\n",
    "FileIO.compute_pd_save(root, root+'/pds', \"jpg\", adv_params, 1, 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run Topo_treatment.ipynb\n",
    "%run Utility_general.ipynb\n",
    "%run Utility_topo.ipynb\n",
    "%run Archpool.ipynb\n",
    "\n",
    "def unbiased_MMD(dist, same):\n",
    "    nl = dist.shape[0]\n",
    "    nr = dist.shape[1]\n",
    "    if same:\n",
    "        assert(nl == nr)\n",
    "        dist_list = []\n",
    "        for i in range(nl):\n",
    "            for j in range(nl):\n",
    "                if i != j:\n",
    "                    dist_list.append(dist[i,j])\n",
    "        sigma = np.median(dist_list)\n",
    "        sigma_sq = sigma * sigma\n",
    "        if sigma_sq == 0.0:\n",
    "            sigma_sq = sigma_sq + 1e-5\n",
    "        summation = 0.0\n",
    "        for i in range(nl):\n",
    "            for j in range(nl):\n",
    "                if i != j:\n",
    "                    summation = summation + math.exp(-dist[i,j]/sigma_sq)\n",
    "        return summation / (nl * (nl - 1))\n",
    "    else:\n",
    "        dist_list = []\n",
    "        for i in range(nl):\n",
    "            for j in range(nr):\n",
    "                dist_list.append(dist[i,j])\n",
    "        sigma = np.median(dist_list)\n",
    "        sigma_sq = sigma * sigma\n",
    "        if sigma_sq == 0.0:\n",
    "            sigma_sq = sigma_sq + 1e-5\n",
    "        summation = 0.0\n",
    "        for i in range(nl):\n",
    "            for j in range(nr):\n",
    "                summation = summation + math.exp(-dist[i,j]/sigma_sq)\n",
    "        return summation / (nl * nr)\n",
    "    \n",
    "def unbiased_MMD_sigma_(dist, same, sigma):\n",
    "    nl = dist.shape[0]\n",
    "    nr = dist.shape[1]\n",
    "    assert(sigma != 0.0)\n",
    "    sigma_sq = sigma * sigma\n",
    "    if same:\n",
    "        assert(nl == nr)\n",
    "        summation = 0.0\n",
    "        for i in range(nl):\n",
    "            for j in range(nl):\n",
    "                if i != j:\n",
    "                    summation = summation + math.exp(-dist[i,j]/sigma_sq)\n",
    "        return summation / (nl * (nl - 1))\n",
    "    else:\n",
    "        summation = 0.0\n",
    "        for i in range(nl):\n",
    "            for j in range(nr):\n",
    "                summation = summation + math.exp(-dist[i,j]/sigma_sq)\n",
    "        return summation / (nl * nr)\n",
    "\n",
    "def compute_unbiased_MMD(folderA, extA, folderB, extB, dim, thresh, proj2dim, wassertein_dist):\n",
    "    adv_params = return_advanced_params()\n",
    "    et = Edges_(adv_params, False)\n",
    "    \n",
    "    img_bat = Utility_general.read_image_subset(folderA, extA, 0.5, shuffle=True)\n",
    "    img_bat = np.stack(img_bat)\n",
    "    B1, D1, pd1, _ = et.pd_batch(img_bat, dim, debug=False, old_form=False, binarize=False, disttrfm=False)\n",
    "    img_bat = Utility_general.read_image_subset(folderB, extB, 0.5, shuffle=True)\n",
    "    img_bat = np.stack(img_bat)\n",
    "    B2, D2, pd2, _ = et.pd_batch(img_bat, dim, debug=False, old_form=False, binarize=False, disttrfm=False)\n",
    "    \n",
    "    if thresh > 0:\n",
    "        B1, D1, pd1 = Utility_topo.topo_filter_retmat_mul(B1, D1, pd1, thresh)\n",
    "        B2, D2, pd2 = Utility_topo.topo_filter_retmat_mul(B2, D2, pd2, thresh)\n",
    "    if proj2dim >= 0:\n",
    "        pd1 = Utility_topo.extract_dim_from_list(pd1, proj2dim)\n",
    "        pd2 = Utility_topo.extract_dim_from_list(pd2, proj2dim)\n",
    "    \n",
    "    distAA, GAA = Utility_general.wasserstein_set_distance(pd1, pd1, wassertein_dist)\n",
    "    distBB, GBB = Utility_general.wasserstein_set_distance(pd2, pd2, wassertein_dist)\n",
    "    distAB, GAB = Utility_general.wasserstein_set_distance(pd1, pd2, wassertein_dist)\n",
    "    \n",
    "    dist_list = []\n",
    "    for i in range(distAA.shape[0]):\n",
    "        for j in range(distAA.shape[0]):\n",
    "            if i != j:\n",
    "                dist_list.append(distAA[i,j])\n",
    "    for i in range(distBB.shape[0]):\n",
    "        for j in range(distBB.shape[0]):\n",
    "            if i != j:\n",
    "                dist_list.append(distBB[i,j])\n",
    "    for i in range(distAB.shape[0]):\n",
    "        for j in range(distAB.shape[1]):\n",
    "            dist_list.append(distAB[i,j])\n",
    "    sigma = np.median(dist_list)\n",
    "    print(sigma)\n",
    "    \n",
    "#     sAA = unbiased_MMD(distAA, True)\n",
    "#     sBB = unbiased_MMD(distBB, True)\n",
    "#     sAB = unbiased_MMD(distAB, False)\n",
    "    \n",
    "    sAA = unbiased_MMD_sigma_(distAA, True, sigma)\n",
    "    sBB = unbiased_MMD_sigma_(distBB, True, sigma)\n",
    "    sAB = unbiased_MMD_sigma_(distAB, False, sigma)\n",
    "    \n",
    "    return sAA + sBB - 2*sAB\n",
    "    \n",
    "compute_unbiased_MMD(\"D:/Data/facades/facade128\", \"jpg\", \"D:/Data/facades/compare0.0005\", \"png\", 1, 1.0, 0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Viewer.ipynb\n",
    "%run Archpool.ipynb\n",
    "# %run Utility_topo.ipynb\n",
    "# %run Utility_general.ipynb\n",
    "%run Topo_treatment.ipynb\n",
    "%run fid/fid_score.ipynb\n",
    "# %run cyckernel/Cyckernel.ipynb\n",
    "#import numpy as np\n",
    "#import cv2\n",
    "\n",
    "# root0 = 'D:/Data/cremi_patch64/cremi_01103.png'\n",
    "# root1 = 'D:/Data/cremi_patch64/cremi_01104.png'\n",
    "# img0 = cv2.imread(root0, cv2.IMREAD_GRAYSCALE)\n",
    "# img1 = cv2.imread(root1, cv2.IMREAD_GRAYSCALE)\n",
    "# # img[img > 0.0] = 255.0\n",
    "# # img[img <= 0.0] = 0.0\n",
    "# img0 = img0.astype(np.uint8)\n",
    "# img1 = img1.astype(np.uint8)\n",
    "\n",
    "# trfm = Utility_general.nz2_nearest_z(img)\n",
    "# print(np.amax(trfm), np.amin(trfm))\n",
    "\n",
    "# adv_params = return_advanced_params()\n",
    "# et = Edges_(adv_params, False)\n",
    "# dist = et.fd_wasserstein_distance('D:/Data/cremi_patch64', 'D:/Data/cremi_patch64', 'png', 1, 1.0, topothresh=1.0)\n",
    "# #dist = et.fd_cycle_distance('D:/Data/cremi_patch64', 'D:/Data/cremi_new/compare0.0005', 'png', topothresh=1.0)\n",
    "# act = np.mean(dist, 1)\n",
    "# mu = np.mean(act, axis=0)\n",
    "# sigma = np.cov(act, rowvar=False)\n",
    "# print(mu, sigma)\n",
    "\n",
    "# act = np.max(dist, 1)\n",
    "# mu = np.mean(act, axis=0)\n",
    "# sigma = np.cov(act, rowvar=False)\n",
    "# print(mu, sigma)\n",
    "\n",
    "# act = np.min(dist, 1)\n",
    "# mu = np.mean(act, axis=0)\n",
    "# sigma = np.cov(act, rowvar=False)\n",
    "# print(mu, sigma)\n",
    "\n",
    "fid = calculate_frechet_distance(1e-5, 1e-5, 58.36175341348612, 1289.0174342325877)\n",
    "print(fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
