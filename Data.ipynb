{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Include.ipynb\n",
    "%run FileIO.ipynb\n",
    "import glob\n",
    "\n",
    "class Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, root, root_pds, target_type, transform=None):\n",
    "        self.root             = root\n",
    "        self.transform        = transform\n",
    "        self.address_book     = []\n",
    "        self.address_book_pds = []\n",
    "        os.chdir(root)\n",
    "        for file in glob.glob(\"*.\"+target_type):\n",
    "            self.address_book.append(os.path.join(root, file))\n",
    "            self.address_book_pds.append(os.path.join(root_pds, file+\".dat\"))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.address_book)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img     = skio.imread(self.address_book[idx])\n",
    "        pd_path = self.address_book_pds[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        instance = {'image': img, 'pd_path': pd_path}\n",
    "        return instance\n",
    "    \n",
    "class Data_fetcher(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def fetch_dataset(name, batch_size, batch_workers, shuffle, drop_last):\n",
    "        if name == \"cifar10\":\n",
    "            dataset = dset.CIFAR10(root=FLAGS.data_path, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.Resize([64, 64]),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                      ]))\n",
    "        elif name == \"custom\":\n",
    "            dataset = Data(FLAGS.data_path, FLAGS.pds_path, FLAGS.data_extension,\n",
    "                  transform=transforms.Compose(\n",
    "                 [transforms.ToPILImage(),\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize([0.5], [0.5])\n",
    "                 ]))\n",
    "        else:\n",
    "            raise NotImplementedError('Unrecognized dataset %s' % name)\n",
    "            \n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                     shuffle=shuffle, num_workers=int(batch_workers), drop_last=drop_last)\n",
    "        return dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
