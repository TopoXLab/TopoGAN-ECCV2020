{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "\n",
    "class Utility_topo(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize_data(images, watershed):\n",
    "        '''\n",
    "        d should have value range between -1.0 and 1.0\n",
    "        (output from tanh() layer).\n",
    "        this function binarize generated images.\n",
    "        '''\n",
    "        d = copy.copy(images)\n",
    "        d = np.squeeze(d)\n",
    "        if len(d.shape) == 2:\n",
    "            d = np.expand_dims(d, axis=0)\n",
    "        d[d >  watershed] = 255.0\n",
    "        d[d <= watershed] = 0.0\n",
    "        d = d.astype(np.uint8)\n",
    "        return d\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_phc_pd_2_persim(phc_pd, dim):\n",
    "        \"\"\" \n",
    "        convert from output of persistent homology [chao version]\n",
    "        to persim style\n",
    "        \"\"\"\n",
    "        assert(dim < len(phc_pd))\n",
    "        num_ = len(phc_pd[dim])\n",
    "        dgm_ = np.zeros([num_, 2])\n",
    "        for i in range(num_):\n",
    "            dgm_[i][0] = phc_pd[dim][i][0]\n",
    "            dgm_[i][1] = phc_pd[dim][i][1]\n",
    "        return dgm_\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_dim_from_list(d, dim):\n",
    "        \"\"\"\n",
    "        extract a single dimension from a list data\n",
    "        d should have form N * [num_ * [dim1, dim2, ...]]\n",
    "        where num_ depends on the particular item\n",
    "        \"\"\"\n",
    "        assert(dim < len(d[0][0]))\n",
    "        N   = len(d)\n",
    "        res = [None] * N\n",
    "        for i in range(N):\n",
    "            l_ = [0.] * len(d[i])\n",
    "            for j in range(len(d[i])):\n",
    "                l_[j] = d[i][j][dim]\n",
    "            res[i] = np.asarray(l_)\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_phc_pd_2_persim_batch(phc_pd, dim_list):\n",
    "        dgm_list = []\n",
    "        for dim in dim_list:\n",
    "            dgm_list.append(Utility_topo.convert_phc_pd_2_persim(phc_pd, dim))\n",
    "        return dgm_list\n",
    "    \n",
    "    # sort bnd or red by persistence, the function is dimension specific\n",
    "    @staticmethod\n",
    "    def sort_persis_results_by_persistence(t, bd, increase=True):\n",
    "        assert(len(t) == len(bd))\n",
    "        set_num = len(t)\n",
    "        \n",
    "        persistence = [0] * set_num\n",
    "        for i in range(set_num):\n",
    "            persistence[i] = bd[i][1] - bd[i][0]\n",
    "        index = sorted(range(set_num), reverse=not increase, key=lambda k: persistence[k])\n",
    "        t_sorted = [None] * set_num\n",
    "        for i in range(set_num):\n",
    "            t_sorted[i] = t[index[i]]\n",
    "        return t_sorted\n",
    "    \n",
    "    @staticmethod\n",
    "    def topo_filter_retindex(pd, threshold):\n",
    "        bat_size = len(pd)\n",
    "        target_topo_index = [None] * bat_size\n",
    "        \n",
    "        for i in range(bat_size):\n",
    "            filtered_index = []\n",
    "            for j in range(len(pd[i])):\n",
    "                # pass if structure birth at 0\n",
    "                if (pd[i][j][0] == 0):\n",
    "                    continue\n",
    "                if (pd[i][j][1] - pd[i][j][0] >= threshold):\n",
    "                    filtered_index.append(j)\n",
    "            target_topo_index[i] = filtered_index\n",
    "            \n",
    "        return target_topo_index\n",
    "    \n",
    "    @staticmethod\n",
    "    def topo_filter_retmat(pd, threshold):\n",
    "        \"\"\"\n",
    "        pd should have form of batch_size * [(num_structure, 2)]\n",
    "        where num_structure depends on the particular item\n",
    "        \"\"\"\n",
    "        bat_size = len(pd)\n",
    "        res_ = []\n",
    "        for i in range(bat_size):\n",
    "            shape_ = pd[i].shape\n",
    "            pd_loc = []\n",
    "            for j in range(shape_[0]):\n",
    "                if pd[i][j][1] - pd[i][j][0] > threshold:\n",
    "                    pd_loc.append(pd[i][j])\n",
    "            res_.append(np.asarray(pd_loc))\n",
    "        return res_\n",
    "    \n",
    "    @staticmethod\n",
    "    def topo_filter_retmat_mul(B, D, PD, threshold):\n",
    "        '''\n",
    "        B, D, PD should be in form of batch_size * [(num_structure, 2)]\n",
    "        which is the new_form outputs.\n",
    "        This function is the same as topo_filter_retmat except that it\n",
    "        filters B, D as well.\n",
    "        '''\n",
    "        bat_size = len(PD)\n",
    "        B_  = []\n",
    "        D_  = []\n",
    "        PD_ = []\n",
    "        for i in range(bat_size):\n",
    "            shape_ = PD[i].shape\n",
    "            b_loc  = []\n",
    "            d_loc  = []\n",
    "            pd_loc = []\n",
    "            assert(B[i].shape[0] == shape_[0])\n",
    "            assert(D[i].shape[0] == shape_[0])\n",
    "            for j in range(shape_[0]):\n",
    "                if PD[i][j, 1] - PD[i][j, 0] > threshold:\n",
    "                    b_loc.append(B[i][j])\n",
    "                    d_loc.append(D[i][j])\n",
    "                    pd_loc.append(PD[i][j])\n",
    "            B_.append(np.asarray(b_loc))\n",
    "            D_.append(np.asarray(d_loc))\n",
    "            PD_.append(np.asarray(pd_loc))\n",
    "            \n",
    "        if len(PD_) < bat_size:\n",
    "            print(\"Warning: some file is killed by filter.\")\n",
    "        return B_, D_, PD_\n",
    "    \n",
    "    @staticmethod\n",
    "    def topo_filter_retmat_bndorred_mul(data, PD, threshold):\n",
    "        '''\n",
    "        Note this function will NOT sort PD itself!\n",
    "        bnd and red(data): batch_num * [num_structure * [point_num * [x, y]]]\n",
    "        '''\n",
    "        bat_size = len(PD)\n",
    "        data_ = []\n",
    "        for i in range(bat_size):\n",
    "            shape_  = PD[i].shape\n",
    "            dat_loc = []\n",
    "            assert(len(data[i]) == shape_[0])\n",
    "            for j in range(shape_[0]):\n",
    "                if PD[i][j, 1] - PD[i][j, 0] > threshold:\n",
    "                    dat_loc.append(data[i][j])\n",
    "            data_.append(dat_loc)\n",
    "            \n",
    "        if len(data_) < bat_size:\n",
    "            print(\"Warning: some file is killed by filter.\")\n",
    "        return data_\n",
    "    \n",
    "    @staticmethod\n",
    "    def gather_sons_bnd_cv(h, father):\n",
    "        '''\n",
    "        gather all son indices for the father\n",
    "        ===== inputs\n",
    "        h: hierachy for single image, output from Utility_topo.compute_bnd_red_cv_batch\n",
    "        father: integer\n",
    "        '''\n",
    "        sons = []\n",
    "        if h[0, father, 2] != -1:\n",
    "            p = h[0,:,3] \n",
    "            for i in range(len(p)):\n",
    "                if p[i] == father:\n",
    "                    sons.append(i)\n",
    "        return sons\n",
    "\n",
    "    @staticmethod\n",
    "    def complete_contours_bnd_cv(h, contours):\n",
    "        '''\n",
    "        complete each structure with its direct sons.\n",
    "        ===== inputs\n",
    "        h: hierachy for single image, output from Utility_topo.compute_bnd_red_cv_batch\n",
    "        contours: boundary or contour for single image, output from Utility_topo.compute_bnd_red_cv_batch\n",
    "        '''\n",
    "        contour_num = len(contours)\n",
    "        contour_cpl = copy.copy(contours)\n",
    "        for i in range(contour_num):\n",
    "            sons = Utility_topo.gather_sons_bnd_cv(h, i)\n",
    "            for j in range(len(sons)):\n",
    "                contour_cpl[i] = np.vstack((contour_cpl[i], contours[sons[j]]))\n",
    "        return contour_cpl\n",
    "    \n",
    "    @staticmethod\n",
    "    def return_countour_with_p_inside(contours, hierarchy, p):\n",
    "        '''\n",
    "        return the contour index with p inside.\n",
    "        contours CANNOT be output from complete_contours_bnd_cv.\n",
    "        '''\n",
    "        contour_num = len(contours)\n",
    "        record = []\n",
    "        pt_num = []\n",
    "        for i in range(contour_num):\n",
    "            if hierarchy[0, i, 3] == -1 and cv2.pointPolygonTest(contours[i], p, False) >= 0:\n",
    "                record.append(i)\n",
    "                pt_num.append(len(contours))\n",
    "        if len(record) == 1:\n",
    "            return record[0]\n",
    "        elif len(record) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            print(\"return_countour_with_p_inside: nested structures detected, return the closest boundary.\")\n",
    "            _, idx = min((min_val, min_idx) for (min_idx, min_val) in enumerate(pt_num))\n",
    "            return record[idx]\n",
    "            \n",
    "    @staticmethod\n",
    "    def dangling_edge_test(label, red, shape, kernel, iter_num, border_width):\n",
    "        mask = np.zeros(shape)\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                if red[1][i][j] == label:\n",
    "                    mask[i][j] = 255\n",
    "        mask_dp = cv2.dilate(mask, kernel, iterations=iter_num)\n",
    "        mask_dp = cv2.erode(mask_dp, kernel, iterations=iter_num)\n",
    "        diff_im = mask_dp - mask\n",
    "        cv2.rectangle(diff_im, (0, 0), (shape[0]-1, shape[0]-1), (0), border_width)\n",
    "        diff_im = diff_im / 255\n",
    "        return np.sum(diff_im)\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_crt_points(crt_, dim):\n",
    "        # dim: designate dimension\n",
    "        # 0-dim: [0], 1-dim: [1], 0 and 1-dim: [0, 1]\n",
    "        data_dims = crt_.size()\n",
    "        birth_x = []\n",
    "        birth_y = []\n",
    "        death_x = []\n",
    "        death_y = []\n",
    "        assert(max(dim) < data_dims)\n",
    "        for item in dim:\n",
    "            for j in range(len(crt_[item])):\n",
    "                birth_x.append(crt_[item][j][0])\n",
    "                birth_y.append(crt_[item][j][1])\n",
    "                death_x.append(crt_[item][j][2])\n",
    "                death_y.append(crt_[item][j][3])\n",
    "        return birth_x, birth_y, death_x, death_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_birth_death_from_crt(crt_, dim):\n",
    "        '''\n",
    "        ===== inputs\n",
    "        crt_ should be in form of dims * [num_structure * [4]] list\n",
    "        dim, integer, the dimension to extract\n",
    "        ===== outputs\n",
    "        b_ and d_ are in form of (num_structure x 2) numpy array\n",
    "        '''\n",
    "        assert(dim < len(crt_))\n",
    "        num_structure = len(crt_[dim])\n",
    "        b_ = np.ones((num_structure, 2))\n",
    "        d_ = np.ones((num_structure, 2))\n",
    "        for i in range(num_structure):\n",
    "            b_[i, 0] = crt_[dim][i][0]\n",
    "            b_[i, 1] = crt_[dim][i][1]\n",
    "            d_[i, 0] = crt_[dim][i][2]\n",
    "            d_[i, 1] = crt_[dim][i][3]\n",
    "        return b_, d_\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_bnd_red_cv(img, low_th, high_th, connectivity):\n",
    "        ret, thresh = cv2.threshold(img,low_th,high_th,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "        red = cv2.connectedComponents(thresh, connectivity, cv2.CV_32S)\n",
    "        return contours, hierarchy, red\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_bnd_red_cv_batch(data):\n",
    "        bat_size = data.shape[0]\n",
    "        bnd_res = [None] * bat_size\n",
    "        hcy_res = [None] * bat_size\n",
    "        red_res = [None] * bat_size\n",
    "        for i in range(bat_size):\n",
    "            bnd_res[i], hcy_res[i], red_res[i] = Utility_topo.compute_bnd_red_cv(data[i,:], 0, 255, 8)\n",
    "        return bnd_res, hcy_res, red_res\n",
    "    \n",
    "    @staticmethod\n",
    "    def dist_trfm_batch(data):\n",
    "        '''\n",
    "        data should be np array with shape (batch_size, height, width)\n",
    "        returns a list: batch_size * [(height*width,)]\n",
    "        '''\n",
    "        assert(len(data.shape) == 3)\n",
    "        assert(type(data[0][0,0] == 'np.uint8'))\n",
    "        bat_size  = data.shape[0]\n",
    "        trfm_list = [None] * bat_size\n",
    "        for i in range(bat_size):\n",
    "            trfm_list[i] = np.concatenate(Utility_general.nz2_nearest_z(data[i,:]))\n",
    "        return trfm_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_dist_homology(dshape, trfm, pc, dim, debug=False, old_form=True):\n",
    "        '''\n",
    "        compute persistence homology at dim, default double type for faster computation\n",
    "        ===== old_form\n",
    "        outputs birth_x_list_, birth_y_list_, death_x_list_, death_y_list_ in a form of \n",
    "        batch_num * [num_structure] and pd_list_ in batch_num * [num_structure * [dim0, dim1, ...]]\n",
    "        ===== not old_form\n",
    "        outputs b_, d_, and pd_ in form of batch_num * [(num_structure, 2)] list\n",
    "        ===== in case of debug\n",
    "        bnd_list_ and red_list_: batch_num * [num_structure * [point_num * [x, y]]]\n",
    "        '''\n",
    "        assert(len(dshape) == 3)\n",
    "        bat_size = dshape[0]\n",
    "        height   = dshape[1]\n",
    "        width    = dshape[2]\n",
    "        \n",
    "        if old_form:\n",
    "            birth_x_list_ = [None] * bat_size\n",
    "            birth_y_list_ = [None] * bat_size\n",
    "            death_x_list_ = [None] * bat_size\n",
    "            death_y_list_ = [None] * bat_size\n",
    "            pd_list_      = [None] * bat_size\n",
    "        else:\n",
    "            B_  = [None] * bat_size\n",
    "            D_  = [None] * bat_size\n",
    "            PD_ = [None] * bat_size\n",
    "        \n",
    "        crt_ = cpp_nested3_IntVector()\n",
    "        pd_  = cpp_nested3_DoubleVector()\n",
    "        flatten_cpp = cpp_nested1_DoubleVector(height * width)\n",
    "        \n",
    "        if debug:\n",
    "            bnd_list_ = [None] * bat_size\n",
    "            red_list_ = [None] * bat_size\n",
    "            bnd_ = cpp_nested4_IntVector()\n",
    "            red_ = cpp_nested4_IntVector()\n",
    "        \n",
    "        for i in range(bat_size):\n",
    "            for j in range(height * width):\n",
    "                flatten_cpp[j] = float(trfm[i][j])\n",
    "            pc.source_from_mat_from_double(\"dummy.dat\", flatten_cpp, height, width)\n",
    "            \n",
    "            pc.run()\n",
    "            pc.return_pers_V(crt_)\n",
    "            pc.return_pers_BD(pd_)\n",
    "            if debug:\n",
    "                pc.return_bnd(bnd_)\n",
    "                pc.return_red(red_)\n",
    "                bnd_[dim] = Utility_topo.sort_persis_results_by_persistence(bnd_[dim], pd_[dim], True)\n",
    "                red_[dim] = Utility_topo.sort_persis_results_by_persistence(red_[dim], pd_[dim], True)\n",
    "                bnd_list_[i] = bnd_[dim]\n",
    "                red_list_[i] = red_[dim]\n",
    "            pc.clear()\n",
    "\n",
    "            crt_[dim] = Utility_topo.sort_persis_results_by_persistence(crt_[dim], pd_[dim], True)\n",
    "            pd_[dim]  = Utility_topo.sort_persis_results_by_persistence(pd_[dim], pd_[dim], True)\n",
    "            \n",
    "            if old_form:\n",
    "                birth_x, birth_y, death_x, death_y = Utility_topo.extract_crt_points(crt_, [dim])\n",
    "                birth_x_list_[i] = birth_x\n",
    "                birth_y_list_[i] = birth_y\n",
    "                death_x_list_[i] = death_x\n",
    "                death_y_list_[i] = death_y\n",
    "                pd_list_[i]      = pd_[dim]\n",
    "            else:      \n",
    "                B_[i], D_[i] = Utility_topo.extract_birth_death_from_crt(crt_, dim)\n",
    "                PD_[i] = np.asarray(pd_[dim])\n",
    "                \n",
    "        if old_form:\n",
    "            if debug:\n",
    "                return birth_x_list_, birth_y_list_, death_x_list_, death_y_list_, pd_list_, bnd_list_, red_list_\n",
    "            else:\n",
    "                return birth_x_list_, birth_y_list_, death_x_list_, death_y_list_, pd_list_\n",
    "        else:\n",
    "            if debug:\n",
    "                return B_, D_, PD_, bnd_list_, red_list_\n",
    "            else:\n",
    "                return B_, D_, PD_\n",
    "        \n",
    "    def topo_force_(set1, set2, G, mapping):\n",
    "        '''\n",
    "        Assume target on the LEFT and reference on the RIGHT.\n",
    "        The result has the same length as set1 but each item\n",
    "        with dim+1 element. The result stores at each item the\n",
    "        location the current point moves to along with the\n",
    "        matching distance.\n",
    "        '''\n",
    "        M   = len(set1)\n",
    "        dim = len(set1[0].shape)             # ONLY WORKS FOR 1 DIM OR 2 DIM\n",
    "        assert(M == len(G))\n",
    "        assert(M == len(mapping))\n",
    "        assert(dim == len(set2[0].shape))\n",
    "\n",
    "        res = [None] * M\n",
    "        for i in range(M):\n",
    "            nl  = G[i].shape[0]\n",
    "            nr  = G[i].shape[1]\n",
    "            m_  = np.ones((nl, dim+1)) * -1\n",
    "            s2_ = set2[mapping[i]]\n",
    "            if dim == 1:\n",
    "                s2_ = np.expand_dims(s2_, axis=1)\n",
    "            if nl > nr:\n",
    "                g_ = np.argmax(G[i], axis=0).astype(np.int64)\n",
    "                for j in range(len(g_)):\n",
    "                    for k in range(dim):\n",
    "                        m_[g_[j], k] = s2_[j, k]\n",
    "                    m_[g_[j], -1] = G[i][g_[j], j]\n",
    "            elif nl <= nr:\n",
    "                g_ = np.argmax(G[i], axis=1).astype(np.int64)\n",
    "                for j in range(len(g_)):\n",
    "                    for k in range(dim):\n",
    "                        m_[j, k] = s2_[g_[j], k]\n",
    "                    m_[j, -1] = G[i][j, g_[j]]\n",
    "            res[i] = m_\n",
    "        return res\n",
    "    \n",
    "    def topo_force_blind_(set1):\n",
    "        '''\n",
    "        Force all persistence dots to the left regardless of the matching.\n",
    "        This version is the same as the CVPR version. Note this version's\n",
    "        death and distance are NOT to be used!!\n",
    "        ===== inputs\n",
    "        set1: batch_num * [(structure_num * dims)] in case of 2 dimensions or\n",
    "              batch_num * [(structure_num,)] in case of 1 dimension\n",
    "        '''\n",
    "        M   = len(set1)\n",
    "        dim = len(set1[0].shape)             # ONLY WORKS FOR 1 DIM OR 2 DIM\n",
    "        \n",
    "        res = [None] * M\n",
    "        for i in range(M):\n",
    "            nl = set1[i].shape[0]\n",
    "            m_ = np.ones((nl, dim+1)) * -1\n",
    "            for j in range(nl):\n",
    "                m_[j, 0] = 0\n",
    "            res[i] = m_\n",
    "        return res\n",
    "    \n",
    "    def apply_force_(b1, force, B_, bnd, hcy, fixN, split_form=False,\n",
    "                     opposite2=False, connect=False, shape=None, thickness=1):\n",
    "        '''\n",
    "        ===== input\n",
    "        b1:    birth time, batch_size * [(num,)]\n",
    "        force: output from Utility_topo.topo_force_, batch_size * [(num, dim + 1)]\n",
    "        B_:    birth coordinates, batch_size * [(num, dim)]\n",
    "        bnd:   output from Utility_topo.compute_bnd_red_cv_batch, batch_size * [struct_num * [point_num * [1 * [x ,y]]]\n",
    "        hcy:   output from Utility_topo.compute_bnd_red_cv_batch, batch_size * [(1, struct_num, 4)]\n",
    "        fixN:  number of points to fix for each critical point\n",
    "        split_form: if True, outputs batch_size * [structure_num * [integers]], else outputs\n",
    "                    batch_size * [integers]\n",
    "        opposite2/connect/shape/thickness: refer to Utility_general.find_closest_N_points\n",
    "        ===== output\n",
    "        flt_list: index of the filtered structures, batch_size * [filtered_num]\n",
    "        force_x_ / force_y_: the coordinates to be changed, batch_size * [filtered_num * [fix_num]]\n",
    "        '''\n",
    "        bat_size = len(b1)\n",
    "        assert(bat_size == len(force))\n",
    "        assert(bat_size == len(B_))\n",
    "\n",
    "        flt_list = [None] * bat_size\n",
    "        force_x_ = [None] * bat_size\n",
    "        force_y_ = [None] * bat_size\n",
    "        for i in range(bat_size):\n",
    "            struct_num = b1[i].shape[0]\n",
    "            file_l_ = []\n",
    "            file_x_ = []\n",
    "            file_y_ = []\n",
    "            bnd_cp  = Utility_topo.complete_contours_bnd_cv(hcy[i], bnd[i])\n",
    "            for j in range(struct_num):\n",
    "                # ==== FILTER ONE =====\n",
    "                if b1[i][j] == 0 or force[i][j,0] != 0:\n",
    "                    continue\n",
    "                # ==== FILTER TWO =====\n",
    "                x_ = B_[i][j,0]\n",
    "                y_ = B_[i][j,1]\n",
    "                ctor_idx = Utility_topo.return_countour_with_p_inside(bnd[i], hcy[i], (x_, y_))\n",
    "                if ctor_idx < 0:\n",
    "                    continue\n",
    "                pts_x, pts_y = Utility_general.find_closest_N_points((x_, y_), bnd_cp[ctor_idx], fixN,\n",
    "                               opposite2=opposite2, connect=connect, shape=shape, thickness=thickness)\n",
    "                file_l_.append(j)\n",
    "                if split_form:\n",
    "                    file_x_.append(pts_x)\n",
    "                    file_y_.append(pts_y)\n",
    "                else:\n",
    "                    file_x_ = file_x_ + pts_x\n",
    "                    file_y_ = file_y_ + pts_y\n",
    "            flt_list[i] = file_l_\n",
    "            force_x_[i] = file_x_\n",
    "            force_y_[i] = file_y_\n",
    "        return flt_list, force_x_, force_y_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
